{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Classes\n",
    "\n",
    "All neccesary classes and start of project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#All neccesary classes for project\n",
    "\n",
    "#general\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#for preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "\n",
    "#for machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#for evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#for utility packages\n",
    "from Utilities.utilities import import_data\n",
    "from Utilities.utilities import DataFrameSelector\n",
    "from Utilities.utilities import CategoricalEncoder\n",
    "from Utilities.utilities import display_scores\n",
    "from Utilities.utilities import pipeline_transform\n",
    "from Utilities.utilities import reset_graph\n",
    "from Utilities.models import DNN_Model\n",
    "from Utilities.models import cross_val_score_dnn\n",
    "from functools import partial\n",
    "\n",
    "#image manipulation\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "import vgg_preprocessing\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import resnet_v2\n",
    "import pnasnet as nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NASNET Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/sdgeo/Dropbox/Own/Programming/Python/MachineLearningDemo/Playground/ml/test_images/dog.png\", 'r+b') as f:\n",
    "    with Image.open(f) as image:\n",
    "        cover = resizeimage.resize_cover(image, [299, 299])\n",
    "        cover.save(\"C:/Users/sdgeo/Dropbox/Own/Programming/Python/MachineLearningDemo/Playground/ml/test_images/dog_shaped.png\", image.format)\n",
    "test_image = mpimg.imread(\"C:/Users/sdgeo/Dropbox/Own/Programming/Python/MachineLearningDemo/Playground/ml/test_images/dog_shaped.png\")[:, :, :3]\n",
    "plt.imshow(test_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "test_image = 2 * test_image - 1\n",
    "X_test = test_image.reshape(1, 299, 299, 3)\n",
    "X_test = X_test.reshape(1,299,299,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_v4 import create_inception_v4\n",
    "reset_graph()\n",
    "\n",
    "def get_file_lists(data_dir):\n",
    "    import glob\n",
    " \n",
    "    train_list = glob.glob(data_dir + '/' + 'train-*')\n",
    "    valid_list = glob.glob(data_dir + '/' + 'validation-*')\n",
    "    if len(train_list) == 0 and \\\n",
    "                    len(valid_list) == 0:\n",
    "        raise IOError('No files found at specified path!')\n",
    "    return train_list, valid_list\n",
    " \n",
    "def parse_record(raw_record, is_training):\n",
    "    \"\"\"Parse an ImageNet record from `value`.\"\"\"\n",
    "    keys_to_features = {\n",
    "        'image/encoded':\n",
    "            tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format':\n",
    "            tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n",
    "        'image/class/label':\n",
    "            tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),\n",
    "        'image/class/text':\n",
    "            tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n",
    "    }\n",
    " \n",
    "    parsed = tf.parse_single_example(raw_record, keys_to_features)\n",
    " \n",
    "    image = tf.image.decode_image(\n",
    "        tf.reshape(parsed['image/encoded'], shape=[]),\n",
    "        3)\n",
    " \n",
    "    # Note that tf.image.convert_image_dtype scales the image data to [0, 1).\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    " \n",
    "    image = tf.image.resize_image_with_crop_or_pad(image,299,299)\n",
    "    \n",
    "    label = tf.cast(\n",
    "        tf.reshape(parsed['image/class/label'], shape=[]),\n",
    "        dtype=tf.int32)\n",
    " \n",
    "    return image, label\n",
    "\n",
    "def get_batch(is_training, filenames, batch_size, num_epochs=1, num_parallel_calls=1):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    " \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=1500)\n",
    " \n",
    "    dataset = dataset.map(lambda value: parse_record(value, is_training),\n",
    "                          num_parallel_calls=num_parallel_calls)\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    " \n",
    "    features, labels = iterator.get_next()\n",
    " \n",
    "    return features, labels\n",
    "\n",
    "def build_iterator(is_training, filenames, batch_size, num_epochs=1000, num_parallel_calls=12):\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "        if is_training:\n",
    "            dataset = dataset.shuffle(buffer_size=1500)\n",
    "\n",
    "        dataset = dataset.map(lambda value: parse_record(value, is_training),\n",
    "                              num_parallel_calls=num_parallel_calls)\n",
    "        dataset = dataset.shuffle(buffer_size=10000)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "\n",
    "def get_values(sess, a,b):\n",
    "    a, b = sess.run([a,b])\n",
    "    return a,b - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, val_list = get_file_lists(\"C:/Users/sdgeo/Dropbox/Own/Programming/Inception/new_categories/tf_record\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 299, 299, 3], name=\"input\")\n",
    "y = tf.placeholder(tf.int32, shape=[None], name=\"output\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name = 'training')\n",
    "bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.01\n",
    "\n",
    "#Here I need to design something to serve as input in order to do training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 500\n",
    "n_hidden2 = 250\n",
    "n_hidden3 = 100\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 25\n",
    "n_hidden6 = 10\n",
    "n_final_layer = 2\n",
    "\n",
    "\n",
    "with slim.arg_scope(nas.pnasnet_large_arg_scope()):\n",
    "    net, end_points = nas.build_pnasnet_large(X, num_classes=1001, is_training=False)\n",
    "    saver = tf.train.Saver()\n",
    "    soft_max_pna = tf.get_default_graph().get_tensor_by_name(\"final_layer/predictions:0\")\n",
    "    last_feature_node = tf.get_default_graph().get_tensor_by_name(\"final_layer/dropout/Identity:0\")\n",
    "\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"DNN_Classifier\"):\n",
    "\n",
    "    stop_layer = tf.stop_gradient(last_feature_node)\n",
    "    hidden1 = tf.layers.dense(stop_layer, n_hidden1, name=\"hidden1\", kernel_initializer=he_init)\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    bn1 = bn_batch_norm_layer(hidden1_drop)\n",
    "    bn1_act = tf.nn.elu(bn1)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\", kernel_initializer=he_init)\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    bn2 = bn_batch_norm_layer(hidden2_drop)\n",
    "    bn2_act = tf.nn.elu(bn2)\n",
    "    \n",
    "    hidden3 = tf.layers.dense(bn2_act, n_hidden3, name=\"hidden3\", kernel_initializer=he_init)\n",
    "    hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "    bn3 = bn_batch_norm_layer(hidden3_drop)\n",
    "    bn3_act = tf.nn.elu(bn3)\n",
    "    \n",
    "    hidden4 = tf.layers.dense(bn3_act, n_hidden4, name=\"hidden4\", kernel_initializer=he_init)\n",
    "    hidden4_drop = tf.layers.dropout(hidden4, dropout_rate, training=training)\n",
    "    bn4 = bn_batch_norm_layer(hidden4_drop)\n",
    "    bn4_act = tf.nn.elu(bn4)\n",
    "    \n",
    "    hidden5 = tf.layers.dense(bn4_act, n_hidden5, name=\"hidden5\", kernel_initializer=he_init)\n",
    "    hidden5_drop = tf.layers.dropout(hidden5, dropout_rate, training=training)\n",
    "    bn5 = bn_batch_norm_layer(hidden5_drop)\n",
    "    bn5_act = tf.nn.elu(bn5)\n",
    "    \n",
    "    hidden6 = tf.layers.dense(bn5_act, n_hidden6, name=\"hidden6\", kernel_initializer=he_init)\n",
    "    hidden6_drop = tf.layers.dropout(hidden6, dropout_rate, training=training)\n",
    "    bn6 = bn_batch_norm_layer(hidden6_drop)\n",
    "    bn6_act = tf.nn.elu(bn6)\n",
    "    \n",
    "    logits_before_bn = tf.layers.dense(bn6_act, n_final_layer, name=\"outputs\")\n",
    "    logits = bn_batch_norm_layer(logits_before_bn, name=\"logits\")\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    \n",
    "    with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        \n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "            \n",
    "saver2 = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filewriter = tf.summary.FileWriter(\"C:/tmp/Cell_Net/current_graph.ckpt\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = get_image('C:/Users/sdgeo/Dropbox/Own/Programming/Inception/ILSVRC/Data/DET/test/ILSVRC2017_test_00000001.jpeg')\n",
    "image = tf.image.decode_jpeg(tf.reshape(image_file, shape=[]),3)\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\n",
    "image_add = vgg_preprocessing.preprocess_image(image=image,output_height=299,output_width=299,is_training=False)\n",
    "image_final = tf.image.resize_image_with_crop_or_pad(image,299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test already exisitng weights for the CNN\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/pnas/model.ckpt')\n",
    "    imag_val = image_final.eval()\n",
    "    imag_val = imag_val.reshape(1,299,299,3)\n",
    "    y_raw = soft_max_pna.eval(feed_dict={X: imag_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/pnas/model.ckpt')\n",
    "    imag_vals, labels = get_batch(False, train_list, 5, num_epochs=1, num_parallel_calls=1)\n",
    "    imag = imag_vals.eval()\n",
    "    y_raw = soft_max_pna.eval(feed_dict={X: imag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_init_variables = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/pnas/model.ckpt')\n",
    "    un_init = set(sess.run(tf.report_uninitialized_variables()))\n",
    "    for var in un_init:\n",
    "        name = var.decode(\"utf-8\")\n",
    "        variable = [var for var in tf.global_variables() if var.op.name==name][0]\n",
    "        un_init_variables.append(variable)\n",
    "\n",
    "init_new_vars_op = tf.initialize_variables(un_init_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/pnas/model.ckpt')\n",
    "    saver2.save(sess, 'C:/tmp/Cell_Net/model_v2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/pnas/model.ckpt')\n",
    "    init_new_vars_op.run()\n",
    "    saver2.save(sess, 'C:/tmp/model_v2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore session and train\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver2.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/model_v2/model_v2.ckpt')\n",
    "    iterator = build_iterator(True, train_list, batch_size, num_epochs=num_epochs, num_parallel_calls=12)    \n",
    "    step = tf.train.global_step(sess, global_step)\n",
    "    next_element = iterator.get_next()\n",
    "    \n",
    "    for step in range(num_epochs):\n",
    "        X_val, y_val = next_element\n",
    "        X_val, y_val = get_values(sess, X_val, y_val)\n",
    "        _, _, acc_sum = sess.run([training_op, extra_update_ops, accuracy_summary], feed_dict={X: X_val, y: y_val})\n",
    "        filewriter.add_summary(acc_sum, step)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 100\n",
    "batch_size = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver2.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/model_v2/model_v2.ckpt')\n",
    "    iterator = build_iterator(True, train_list, batch_size, num_epochs=num_epochs, num_parallel_calls=12)    \n",
    "    step = tf.train.global_step(sess, global_step)\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    X_val, y_val = next_element\n",
    "    X_val, y_val = get_values(sess, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test already exisitng weights for the CNN\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, 'C:/tmp/Cell_Net/model_v2.ckpt')\n",
    "    \n",
    "    imag_val = image_final.eval()\n",
    "    imag_val = imag_val.reshape(1,299,299,3)\n",
    "    y_raw = soft_max_pna.eval(feed_dict={X: imag_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(y_raw)\n",
    "item = frame.iloc[0,:]\n",
    "item = np.argmax(item)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = Image.fromarray(np.uint8(X_val[0] * 255), 'RGB')\n",
    "\n",
    "pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(filenames(False, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/ILSVRC/Data/DET/test/'))\n",
    "dataset = dataset.flat_map(tf.data.TFRecordDataset)\n",
    "dataset = dataset.map(lambda value: record_parser(value, False),num_parallel_calls=5)\n",
    "dataset = dataset.prefetch(1)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "image, label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing a metagraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the graph the first time\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('C:/Users/sdgeo/Dropbox/Own/Programming/Inception/resnet_v2_checkpoints/model.ckpt-250200.meta')\n",
    "    new_saver.restore(sess, 'C:/Users/sdgeo/Dropbox/Own/Programming/Inception/resnet_v2_checkpoints/model.ckpt-250200')\n",
    "    #Check what variables are left uninitialized after loading checkpoint\n",
    "    uninitialized_variables = set(sess.run(tf.report_uninitialized_variables()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the graph after\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    saver.restore(sess, \"C:/Users/sdgeo/Dropbox/Own/Programming/Inception/resnet_v2_checkpoints/model.ckpt-250200\")\n",
    "    #Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
