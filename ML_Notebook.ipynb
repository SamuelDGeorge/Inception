{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Classes\n",
    "\n",
    "All neccesary classes and start of project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccesary classes for project\n",
    "\n",
    "#general\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#for preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "\n",
    "#for machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#for evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#for utility packages\n",
    "from Utilities.utilities import import_data\n",
    "from Utilities.utilities import DataFrameSelector\n",
    "from Utilities.utilities import CategoricalEncoder\n",
    "from Utilities.utilities import display_scores\n",
    "from Utilities.utilities import pipeline_transform\n",
    "from Utilities.utilities import reset_graph\n",
    "from Utilities.models import DNN_Model\n",
    "from Utilities.models import cross_val_score_dnn\n",
    "\n",
    "#image manipulation\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "TF_BACKEND_TF_DIM_ORDERING = \"C:/Users/sdgeo/Dropbox/Own/Programming/Inception/weights/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build resnet V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/sdgeo/Dropbox/Own/Programming/Python/MachineLearningDemo/Playground/ml/test_images/dog.png\", 'r+b') as f:\n",
    "    with Image.open(f) as image:\n",
    "        cover = resizeimage.resize_cover(image, [299, 299])\n",
    "        cover.save(\"C:/Users/sdgeo/Dropbox/Own/Programming/Python/MachineLearningDemo/Playground/ml/test_images/dog_shaped.png\", image.format)\n",
    "test_image = mpimg.imread(\"C:/Users/sdgeo/Dropbox/Own/Programming/Python/MachineLearningDemo/Playground/ml/test_images/dog_shaped.png\")[:, :, :3]\n",
    "plt.imshow(test_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "test_image = 2 * test_image - 1\n",
    "X_test = test_image.reshape(1, 299, 299, 3)\n",
    "X_test = X_test.reshape(1,299,299,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_v4 import create_inception_v4\n",
    "reset_graph()\n",
    "\n",
    "model = create_inception_v4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_file('inception_v4_weights_tf_dim_ordering_tf_kernels.h5', TF_BACKEND_TF_DIM_ORDERING,\n",
    "                                   cache_subdir='models')\n",
    "model.load_weights(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filewriter = tf.summary.FileWriter(\"current_graph.ckpt\", tf.get_default_graph())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    block = set(sess.run(tf.report_uninitialized_variables()))\n",
    "    print(len(block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    items = tf.global_variables()\n",
    "    print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    tf.variables_initializer(\n",
    "        [v for v in tf.global_variables() if v.name.split(':')[0] in set(sess.run(tf.report_uninitialized_variables()))\n",
    "    ])\n",
    "    saver.save(sess, \"current_run.ckpt\")\n",
    "    trainable = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    init.run()\n",
    "    saver.save(sess, \"C:/Users/sdgeo/Dropbox/Own/Programming/Inception/Inception/my_inception.ckpt\")\n",
    "    X_tensor = tf.get_default_graph().get_tensor_by_name(\"input_1:0\")\n",
    "    dense_layer = tf.get_default_graph().get_tensor_by_name(\"dense_1/Softmax:0\")\n",
    "    y_raw = dense_layer.eval(feed_dict={X_tensor: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    saver.restore(sess, \"C:/Users/sdgeo/Dropbox/Own/Programming/Inception/Inception/my_inception.ckpt\")\n",
    "    X_tensor = tf.get_default_graph().get_tensor_by_name(\"input_1:0\")\n",
    "    dense_layer = tf.get_default_graph().get_tensor_by_name(\"dense_1/Softmax:0\")\n",
    "    y_raw = dense_layer.eval(feed_dict={X_tensor: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(y_raw)\n",
    "item = np.argmax(y_raw)\n",
    "y_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the training Data\n",
    "\n",
    "Here the data is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data\n",
    "\n",
    "raw_data = import_data(\"richard_rppa_labeled_raw2.csv\", \"C:/Users/sdgeo/Dropbox/Der Lab/Data/RichardRPPA/raw_data\").drop(\"Unnamed: 0\", axis=1).drop(\"replicate\", axis=1)\n",
    "#raw_data_subsets = import_data(\"protein_list_final_final.csv\")\n",
    "\n",
    "#For doing NS v KRAS\n",
    "raw_data_KRAS = raw_data.loc[raw_data[\"target\"] == 'KRAS_'].drop(\"target\", axis=1).reset_index().drop(\"index\", axis=1)\n",
    "raw_data_KRAS[\"construct\"] = raw_data_KRAS[\"construct\"].replace('si1', 'KD')\n",
    "raw_data_KRAS[\"construct\"] = raw_data_KRAS[\"construct\"].replace('si2', 'KD')\n",
    "\n",
    "#For doing NS v MYC\n",
    "raw_data_MYC = raw_data.loc[raw_data[\"target\"] == 'MYC_'].drop(\"target\", axis=1).reset_index().drop(\"index\", axis=1)\n",
    "raw_data_MYC[\"construct\"] = raw_data_MYC[\"construct\"].replace('si1', 'KD')\n",
    "raw_data_MYC[\"construct\"] = raw_data_MYC[\"construct\"].replace('si2', 'KD')\n",
    "\n",
    "\n",
    "#For Doing Cell Line\n",
    "raw_data_all = raw_data.drop(\"target\", axis=1).drop(\"construct\", axis=1)\n",
    "\n",
    "#For doing both NS vs KRAS and MYC\n",
    "raw_data_KVM = raw_data.copy()\n",
    "raw_data_KVM[\"construct\"] = raw_data_KVM[\"construct\"].replace('si1', 'KD')\n",
    "raw_data_KVM[\"construct\"] = raw_data_KVM[\"construct\"].replace('si2', 'KD')\n",
    "raw_data_KVM[\"treatment\"] = raw_data_KVM[\"target\"] + raw_data_KVM[\"construct\"]\n",
    "cols = list(raw_data_KVM)\n",
    "cols.insert(1, cols.pop(cols.index('treatment')))\n",
    "raw_data_KVM = raw_data_KVM.loc[:, cols].drop(\"target\", axis=1).drop(\"construct\", axis=1).reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "#For doing KRAS-KD vs MYC-KD\n",
    "raw_data_KVM_ONLY = raw_data.copy().loc[raw_data[\"construct\"] != 'NS']\n",
    "raw_data_KVM_ONLY[\"construct\"] = raw_data_KVM_ONLY[\"construct\"].replace('si1', 'KD')\n",
    "raw_data_KVM_ONLY[\"construct\"] = raw_data_KVM_ONLY[\"construct\"].replace('si2', 'KD')\n",
    "raw_data_KVM_ONLY[\"treatment\"] = raw_data_KVM_ONLY[\"target\"] + raw_data_KVM_ONLY[\"construct\"]\n",
    "cols = list(raw_data_KVM_ONLY)\n",
    "cols.insert(1, cols.pop(cols.index('treatment')))\n",
    "raw_data_KVM_ONLY = raw_data_KVM_ONLY.loc[:, cols].drop(\"target\", axis=1).drop(\"construct\", axis=1).reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "#For doing NSK vs NSM\n",
    "raw_data_NS = raw_data_KVM.loc[raw_data_KVM['treatment'] != 'KRAS_KD']\n",
    "raw_data_NS = raw_data_NS.loc[raw_data_NS['treatment'] != 'MYC_KD'].reset_index().drop(\"index\", axis=1)\n",
    "raw_data_NS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Machine Learning\n",
    "\n",
    "This work flow will break apart a training set and test set as well as put the data through a pipeline to prepare it for fitting to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(raw_data_all, raw_data_all[\"cell.line\"]):\n",
    "    strat_train = raw_data_all.loc[train_index]\n",
    "    strat_test = raw_data_all.loc[test_index]\n",
    "    \n",
    "for train_index, test_index in split.split(raw_data_KVM, raw_data_KVM[\"cell.line\"]):\n",
    "    strat_train_KVM = raw_data_KVM.loc[train_index]\n",
    "    strat_test_KVM = raw_data_KVM.loc[test_index]\n",
    "    \n",
    "for train_index, test_index in split.split(raw_data_KVM_ONLY, raw_data_KVM_ONLY[\"cell.line\"]):\n",
    "    strat_train_KVM_ONLY = raw_data_KVM_ONLY.loc[train_index]\n",
    "    strat_test_KVM_ONLY = raw_data_KVM_ONLY.loc[test_index]\n",
    "\n",
    "\n",
    "for train_index, test_index in split.split(raw_data_KRAS, raw_data_KRAS[\"cell.line\"]):\n",
    "    strat_train_KRAS = raw_data_KRAS.loc[train_index]\n",
    "    strat_test_KRAS = raw_data_KRAS.loc[test_index]\n",
    "\n",
    "for train_index, test_index in split.split(raw_data_MYC, raw_data_MYC[\"cell.line\"]):\n",
    "    strat_train_MYC = raw_data_MYC.loc[train_index]\n",
    "    strat_test_MYC = raw_data_MYC.loc[test_index]\n",
    "    \n",
    "for train_index, test_index in split.split(raw_data_NS, raw_data_NS[\"cell.line\"]):\n",
    "    strat_train_NS = raw_data_NS.loc[train_index]\n",
    "    strat_test_NS = raw_data_NS.loc[test_index]\n",
    "\n",
    "    \n",
    "strat_train_NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_Line\n",
    "raw_train_cell = strat_train.drop(\"cell.line\", axis=1)\n",
    "train_labels_cell = pd.DataFrame(strat_train[\"cell.line\"].copy())\n",
    "\n",
    "raw_test_cell = strat_test.drop(\"cell.line\", axis=1)\n",
    "test_labels_cell = pd.DataFrame(strat_test[\"cell.line\"].copy())\n",
    "\n",
    "#KRAS vs MYC All\n",
    "raw_train_KVM = strat_train_KVM.drop(\"treatment\", axis=1)\n",
    "train_labels_KVM = pd.DataFrame(strat_train_KVM[\"treatment\"].copy())\n",
    "\n",
    "raw_test_KVM = strat_test_KVM.drop(\"treatment\", axis=1)\n",
    "test_labels_KVM = pd.DataFrame(strat_test_KVM[\"treatment\"].copy())\n",
    "\n",
    "#KRAS vs MYC Only\n",
    "raw_train_KVM_ONLY = strat_train_KVM_ONLY.drop(\"treatment\", axis=1)\n",
    "train_labels_KVM_ONLY = pd.DataFrame(strat_train_KVM_ONLY[\"treatment\"].copy())\n",
    "\n",
    "raw_test_KVM_ONLY = strat_test_KVM_ONLY.drop(\"treatment\", axis=1)\n",
    "test_labels_KVM_ONLY = pd.DataFrame(strat_test_KVM_ONLY[\"treatment\"].copy())\n",
    "\n",
    "#KRAS_Treatment\n",
    "raw_train_KRAS = strat_train_KRAS.drop(\"construct\", axis=1)\n",
    "train_labels_KRAS = pd.DataFrame(strat_train_KRAS[\"construct\"].copy())\n",
    "\n",
    "raw_test_KRAS = strat_test_KRAS.drop(\"construct\", axis=1)\n",
    "test_labels_KRAS = pd.DataFrame(strat_test_KRAS[\"construct\"].copy())\n",
    "\n",
    "#MYC_Treatment\n",
    "raw_train_MYC = strat_train_MYC.drop(\"construct\", axis=1)\n",
    "train_labels_MYC = pd.DataFrame(strat_train_MYC[\"construct\"].copy())\n",
    "\n",
    "raw_test_MYC = strat_test_MYC.drop(\"construct\", axis=1)\n",
    "test_labels_MYC = pd.DataFrame(strat_test_MYC[\"construct\"].copy())\n",
    "\n",
    "#NS\n",
    "raw_train_NS = strat_train_NS.drop(\"treatment\", axis=1)\n",
    "train_labels_NS = pd.DataFrame(strat_train_NS[\"treatment\"].copy())\n",
    "\n",
    "raw_test_NS = strat_test_NS.drop(\"treatment\", axis=1)\n",
    "test_labels_NS = pd.DataFrame(strat_test_NS[\"treatment\"].copy())\n",
    "\n",
    "\n",
    "\n",
    "raw_train_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell Line\n",
    "train_cell = pipeline_transform(raw_train_cell)\n",
    "test_cell = pipeline_transform(raw_test_cell)\n",
    "\n",
    "#Kras vs Myc All\n",
    "train_KVM = pipeline_transform(raw_train_KVM)\n",
    "test_KVM = pipeline_transform(raw_test_KVM)\n",
    "\n",
    "#Kras vs Myc Only\n",
    "train_KVM_ONLY = pipeline_transform(raw_train_KVM_ONLY)\n",
    "test_KVM_ONLY = pipeline_transform(raw_test_KVM_ONLY)\n",
    "\n",
    "#KRAS\n",
    "train_KRAS = pipeline_transform(raw_train_KRAS)\n",
    "test_KRAS = pipeline_transform(raw_test_KRAS)\n",
    "\n",
    "#MYC\n",
    "train_MYC = pipeline_transform(raw_train_MYC)\n",
    "test_MYC = pipeline_transform(raw_test_MYC)\n",
    "\n",
    "#NS\n",
    "train_NS = pipeline_transform(raw_train_NS)\n",
    "test_NS = pipeline_transform(raw_test_NS)\n",
    "\n",
    "\n",
    "train_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready for Machine Learning:\n",
    "\n",
    "At this point the data is in the proper format for training your model. Relevant variables listed below:\n",
    "\n",
    "The Training Data:\n",
    "\n",
    "x_train_data - The X in your model. These are what we are going to use to make predictions. \n",
    "\n",
    "y_train_data - The Y in your model. These are the values you are going to try and predict.\n",
    "\n",
    "The Test Data:\n",
    "\n",
    "x_test_data - The X data for your test data. Use this to test your completed model \n",
    "\n",
    "y_test_data - the Y data for your test data. Use this to test your model againt real predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_KVM_ONLY\n",
    "Y_train = train_labels_KVM_ONLY\n",
    "\n",
    "X_test = test_KVM_ONLY\n",
    "Y_test = test_labels_KVM_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a decision Tree\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=150)\n",
    "tree_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the tree\n",
    "\n",
    "export_graphviz(\n",
    "    tree_clf,\n",
    "    out_file=\"C:/Users/sdgeo/Dropbox/Der Lab/Data/RichardRPPA/RPPA_Analysis/decision_tree_KVM_ONLY.dot\",\n",
    "    feature_names=list(X_train.columns.values),\n",
    "    class_names=list(map(str, tree_clf.classes_)),\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "os.system(\"dot -Tpng decision_tree_KVM_ONLY.dot -o decision_tree_KVM_ONLY.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the tree\n",
    "\n",
    "export_graphviz(\n",
    "    tree_clf_cell,\n",
    "    out_file=\"C:/Users/sdgeo/Dropbox/Der Lab/Data/IremRPPA/decision_tree_cell.dot\",\n",
    "    feature_names=list(cell_train.columns.values),\n",
    "    class_names=classes_cell,\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "os.system(\"dot -Tpng decision_tree_cell.dot -o decision_tree_cell.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree_clf.predict(X_test)\n",
    "confusion_matrix(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(pred, Y_test, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model with RandomSearchCV\n",
    "\n",
    "\n",
    "Uses a random forest and GridSearchCV to predict the hyperparameters and generate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_KVM_ONLY\n",
    "Y_train = train_labels_KVM_ONLY\n",
    "\n",
    "X_test = test_KVM_ONLY\n",
    "Y_test = test_labels_KVM_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a random search for best iterations\n",
    "\n",
    "param_grid_random = {\n",
    "        'n_estimators': list(range(300,400)),\n",
    "        'max_features': list(range(30,150)),\n",
    "    }\n",
    "\n",
    "forest_reg_rand_clf = RandomForestClassifier(bootstrap = True)\n",
    "\n",
    "for_random_clf = RandomizedSearchCV(forest_reg_rand_clf, param_distributions=param_grid_random,\n",
    "                                n_iter=1000, cv=5, scoring='f1_macro',\n",
    "                                verbose=2, n_jobs=-1, random_state=42)\n",
    "\n",
    "\n",
    "for_random_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models\n",
    "\n",
    "Use this to save any models that you have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to save a model\n",
    "\n",
    "pickle.dump(for_random_clf, open('C:/Users/sdgeo/Dropbox/Der Lab/Data/RichardRPPA/models/random_forest_MYC.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can load it with this code\n",
    "\n",
    "loaded_model = pickle.load(open('C:/Users/sdgeo/Dropbox/Der Lab/Data/RichardRPPA/models/random_forest_MYC.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.best_estimator_.predict(X_test)\n",
    "score = f1_score(pred,Y_test, average='macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Fits \n",
    "\n",
    "Test to see if the fits are good and give metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_MYC\n",
    "Y_train = train_labels_MYC\n",
    "\n",
    "X_test = test_MYC\n",
    "Y_test = test_labels_MYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_found = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_found.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_importances = search_found.best_estimator_.feature_importances_\n",
    "sorted(zip(feature_importances, X_train.columns.values), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(search_found.best_estimator_, X_train, Y_train, scoring=\"f1_macro\", cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search_found.best_estimator_.predict(X_test)\n",
    "confusion_matrix(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(pred, Y_test, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 4)\n",
    "X2D = pca.fit_transform(X_train)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clustering_data_train = pipeline_transform(X_train, scaler=True)\n",
    "clustering_data_test = pipeline_transform(X_test, scaler=True)\n",
    "clustering_data_train_labels = Y_train.reset_index().drop(\"index\", axis=1)\n",
    "clustering_data_test_labels = Y_test.reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "clustering_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(clustering_data_train)\n",
    "predicted = kmeans.predict(clustering_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_train_post = clustering_data_train.copy()\n",
    "clustering_train_post[\"cluster\"] = kmeans.labels_\n",
    "clustering_train_post[\"cell.line\"] = clustering_data_train_labels[\"cell.line\"]\n",
    "\n",
    "clustering_test_post = clustering_data_test.copy()\n",
    "clustering_test_post[\"cluster\"] = predicted\n",
    "clustering_test_post[\"cell.line\"] = clustering_data_test_labels[\"cell.line\"]\n",
    "\n",
    "clustering_test_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_train_post = clustering_train_post.copy()\n",
    "cluster_train_post[\"cell.line\"] = cluster_train_post[\"cell.line\"].replace(['PANC1'], 3)\n",
    "cluster_train_post[\"cell.line\"] = cluster_train_post[\"cell.line\"].replace(['Pa02C'], 0)\n",
    "cluster_train_post[\"cell.line\"] = cluster_train_post[\"cell.line\"].replace(['Pa14C'], 4)\n",
    "cluster_train_post[\"cell.line\"] = cluster_train_post[\"cell.line\"].replace(['HPAFII'], 2)\n",
    "cluster_train_post[\"cell.line\"] = cluster_train_post[\"cell.line\"].replace(['Pa16C'], 1)\n",
    "\n",
    "cluster_test_post = clustering_test_post.copy()\n",
    "cluster_test_post[\"cell.line\"] = cluster_test_post[\"cell.line\"].replace(['PANC1'], 3)\n",
    "cluster_test_post[\"cell.line\"] = cluster_test_post[\"cell.line\"].replace(['Pa02C'], 0)\n",
    "cluster_test_post[\"cell.line\"] = cluster_test_post[\"cell.line\"].replace(['Pa14C'], 4)\n",
    "cluster_test_post[\"cell.line\"] = cluster_test_post[\"cell.line\"].replace(['HPAFII'], 2)\n",
    "cluster_test_post[\"cell.line\"] = cluster_test_post[\"cell.line\"].replace(['Pa16C'], 1)\n",
    "\n",
    "cluster_test_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_test_post.plot(kind=\"scatter\", x=\"cell.line\", y=\"cluster\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_corr = ss.spearmanr(cluster_test_post[\"cell.line\"], cluster_test_post[\"cluster\"])\n",
    "cell_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN\n",
    "\n",
    "Here we will build a 2 layer neural network and see what the best predictability possible is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = pipeline_transform(train_NS, scaler=True).as_matrix()\n",
    "Y_train_tensor = train_labels_NS.copy()\n",
    "Y_train_tensor['treatment'] = train_labels_NS['treatment'].replace('KRAS_NS', 0)\n",
    "Y_train_tensor['treatment'] = Y_train_tensor['treatment'].replace('MYC_NS', 1)\n",
    "Y_train_tensor = Y_train_tensor.as_matrix()[:, 0]\n",
    "\n",
    "X_test_tensor = pipeline_transform(test_NS, scaler=True).as_matrix()\n",
    "Y_test_tensor = test_labels_NS.copy()\n",
    "Y_test_tensor['treatment'] = test_labels_NS['treatment'].replace('KRAS_NS', 0)\n",
    "Y_test_tensor['treatment'] = Y_test_tensor['treatment'].replace('MYC_NS', 1)\n",
    "Y_test_tensor = Y_test_tensor.as_matrix()[:, 0]\n",
    "\n",
    "Y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_Model(n_outputs=4, log_dir=\"C:/tmp/RichardRPPA/tf_logs_NS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score_dnn(model, X_train_tensor, Y_train_tensor)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.mean(scores)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tensor)\n",
    "score = f1_score(y_pred, Y_test_tensor, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Regressor fits\n",
    "\n",
    "Here are going to build yet another model and find how good its fit is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test a basic model using cross_val_score\n",
    "\n",
    "svm_reg = SVR()\n",
    "\n",
    "svm_reg.fit(prepared_data, data_labels)\n",
    "kir_scores = cross_val_score(svm_reg, prepared_data, data_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svm_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use random search here to optomize SVM\n",
    "\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'C': list(range(1,1000)),\n",
    "        'gamma': expon(scale=1.0),\n",
    "        'degree': list(range(1,4)),\n",
    "        'coef0': [1]\n",
    "    }\n",
    "\n",
    "y_train_data_short = (y_train_data == 'Pa02C')\n",
    "\n",
    "svm_reg = SVR()\n",
    "svm_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=2000, cv=3, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, n_jobs=4, random_state=42)\n",
    "svm_search.fit(x_train_data, y_train_data_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo_clf = OneVsOneClassifier(SVR(C=226, coef0=1, degree=1, gamma= 0.349, kernel='rbf'))\n",
    "\n",
    "#Use random search here to optomize SVM\n",
    "\n",
    "ovo_clf.fit(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mse = svm_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the parameters you would like to see how well any regression performs\n",
    "\n",
    "Here you can test your differnt models to see how well the model fits the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare and select data from test set\n",
    "\n",
    "#final_model = search_found.best_estimator_\n",
    "#final_model = for_clf\n",
    "#final_model = loaded_model\n",
    "final_model = ovo_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at predictions rmse\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(Y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = final_model.predict(x_test_data)\n",
    "score = f1_score(y_test_data, final_predictions, average='macro')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test binary evaluation with treatment status\n",
    "\n",
    "Y_test_cond = (Y_test > .5)\n",
    "pred_cond = (final_predictions > .5 )\n",
    "confusion_matrix(Y_test_cond, pred_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(Y_test_cond, pred_cond)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(final_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plot_data = pd.DataFrame(X_test_prepared)\n",
    "plot_data.hist(bins=20, figsize=(40,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
